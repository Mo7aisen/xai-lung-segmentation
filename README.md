# ğŸ« XAI Lung Segmentation Analysis

> **Explainable AI for Medical Image Segmentation with Interactive Analysis Dashboard**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red)](https://pytorch.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.0%2B-ff6b6b)](https://streamlit.io)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“‹ Overview

This project implements a comprehensive **Explainable AI (XAI) framework** for lung segmentation in chest X-ray images, featuring an interactive analysis dashboard for comparative model evaluation. The system combines state-of-the-art deep learning models with advanced attribution methods to provide interpretable insights into model decision-making processes.

### ğŸ¯ Key Features

- **ğŸ”¬ Interactive XAI Dashboard**: Professional Streamlit-based interface for comparative analysis
- **ğŸ§  Multiple Model Support**: U-Net architectures with various training configurations
- **ğŸ“Š Advanced Attribution Methods**: Integrated Gradients with uncertainty quantification
- **ğŸ“ˆ Comparative Analysis**: Side-by-side evaluation of different model states
- **ğŸšï¸ Real-time Visualization**: Dynamic threshold adjustment and overlay visualization
- **ğŸ“¤ Export Capabilities**: Comprehensive result export for research workflows
- **ğŸ”„ Version Control**: Professional Git workflow with organized project structure

## ğŸ—ï¸ Project Structure

```
xai/
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸ“ models/                   # Model architectures
â”‚   â”‚   â””â”€â”€ model.py                 # U-Net implementation
â”‚   â”œâ”€â”€ ğŸ“ data/                     # Data handling
â”‚   â”‚   â””â”€â”€ data_loader.py           # Dataset loaders
â”‚   â”œâ”€â”€ ğŸ“ training/                 # Training scripts
â”‚   â”‚   â”œâ”€â”€ train.py                 # Basic training
â”‚   â”‚   â””â”€â”€ train_extended.py        # Extended training pipeline
â”‚   â”œâ”€â”€ ğŸ“ evaluation/               # Evaluation modules
â”‚   â”‚   â””â”€â”€ evaluate.py              # Model evaluation
â”‚   â”œâ”€â”€ ğŸ“ visualization/            # Interactive dashboards
â”‚   â”‚   â”œâ”€â”€ app.py                   # Basic dashboard
â”‚   â”‚   â””â”€â”€ app_enhanced.py          # Enhanced XAI dashboard
â”‚   â””â”€â”€ ğŸ“ utils/                    # Utility functions
â”‚       â”œâ”€â”€ utils.py                 # General utilities
â”‚       â”œâ”€â”€ validation.py            # Validation functions
â”‚       â”œâ”€â”€ generate_split_manifest.py
â”‚       â””â”€â”€ organize_model_checkpoints.py
â”œâ”€â”€ ğŸ“ scripts/                      # Automation scripts
â”‚   â”œâ”€â”€ master_pipeline.sh           # Main pipeline
â”‚   â”œâ”€â”€ continue_pipeline.sh         # Resume training
â”‚   â”œâ”€â”€ run_training.sh              # Training execution
â”‚   â”œâ”€â”€ run_evaluation.sh            # Evaluation execution
â”‚   â”œâ”€â”€ run_extended_training.sh     # Extended training
â”‚   â”œâ”€â”€ run_extended_evaluation.sh   # Extended evaluation
â”‚   â”œâ”€â”€ monitor_progress.sh          # Progress monitoring
â”‚   â”œâ”€â”€ setup_project.sh             # Project setup
â”‚   â””â”€â”€ legacy_scripts.py            # Legacy utilities
â”œâ”€â”€ ğŸ“ config/                       # Configuration files
â”‚   â”œâ”€â”€ config.yaml                  # Main configuration
â”‚   â””â”€â”€ config_extended.yaml         # Extended config
â”œâ”€â”€ ğŸ“ outputs/                      # Training outputs
â”‚   â”œâ”€â”€ ğŸ“ model_checkpoints/        # Saved models
â”‚   â”œâ”€â”€ ğŸ“ evaluation_results/       # Evaluation data
â”‚   â””â”€â”€ ğŸ“ xai_maps/                 # Attribution maps
â”œâ”€â”€ ğŸ“ exports/                      # Exported analysis results
â”œâ”€â”€ ğŸ“ tests/                        # Unit tests
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”œâ”€â”€ ğŸ“ assets/                       # Static assets
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                       # Git ignore rules
â””â”€â”€ README.md                        # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **CUDA-capable GPU** (recommended)
- **Git** for version control

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/xai-lung-segmentation.git
   cd xai-lung-segmentation
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure datasets**
   ```bash
   cp config/config.template.yaml config/config.yaml
   # Edit config/config.yaml with your dataset paths
   ```

### ğŸ® Usage

#### 1. **Interactive XAI Dashboard**
Launch the enhanced analysis dashboard:
```bash
streamlit run src/visualization/app_enhanced.py
```

**Features:**
- **Three-column comparative analysis**
- **Real-time segmentation threshold adjustment**
- **Interactive pixel selection with coordinate controls**
- **Professional attribution visualizations**
- **Export functionality for research workflows**

#### 2. **Training Pipeline**
Run the complete training pipeline:
```bash
bash scripts/master_pipeline.sh
```

#### 3. **Model Evaluation**
Evaluate trained models:
```bash
bash scripts/run_extended_evaluation.sh
```

## ğŸ“Š Datasets

The project supports multiple chest X-ray datasets:

- **ğŸ¥ JSRT Dataset**: Japanese Society of Radiological Technology
- **ğŸ¥ Montgomery Dataset**: Montgomery County chest X-ray dataset
- **ğŸ”§ Custom datasets**: Configurable through YAML files

### Dataset Configuration

Edit `config/config.yaml`:
```yaml
datasets:
  jsrt:
    path: "/path/to/jsrt"
    images: "images"
    masks: "masks"
  montgomery:
    path: "/path/to/montgomery"
    images: "CXR_png"
    masks: "ManualMask"
```

## ğŸ§  Model Architecture

### U-Net Implementation
- **Encoder**: Progressive downsampling with skip connections
- **Decoder**: Progressive upsampling with concatenation
- **Output**: Sigmoid activation for binary segmentation

### Training Configurations
- **Full Dataset**: Complete training data
- **Half Dataset**: 50% of training data for comparison
- **Multiple Epochs**: 50, 150, 250+ epoch configurations

## ğŸ“ˆ XAI Methods

### Integrated Gradients
- **Attribution computation** for pixel-level explanations
- **Baseline integration** with multiple baselines
- **Uncertainty quantification** via Monte Carlo dropout

### Visualization Features
- **Heatmap overlays** with customizable colormaps
- **Cumulative attribution analysis** with distance-based weighting
- **Professional histogram displays** for distribution analysis

## ğŸ”§ Configuration

### Environment Variables
```bash
export OUTPUT_DIR="/path/to/outputs"
export DATA_PATH="/path/to/datasets"
export MONTGOMERY_PATH="/path/to/montgomery"
export JSRT_PATH="/path/to/jsrt"
```

### YAML Configuration
See `config/config.yaml` for detailed configuration options.

## ğŸ“¤ Export & Analysis

The dashboard supports comprehensive result export:

- **ğŸ“Š Metrics**: CSV format with quantitative results
- **ğŸ–¼ï¸ Visualizations**: PNG format for figures
- **ğŸ’¾ Raw Data**: NPY/NPZ format for attribution maps
- **ğŸ“‹ Comparison Reports**: JSON format for multi-model analysis

## ğŸ§ª Testing

Run the test suite:
```bash
python -m pytest tests/
```

## ğŸ“ Documentation

Additional documentation available in the `docs/` directory:

- **ğŸ—ï¸ Architecture Guide**: Detailed model architecture
- **ğŸ”¬ XAI Methods**: Explanation of attribution techniques
- **ğŸ¨ UI Guide**: Dashboard usage instructions
- **ğŸš€ Deployment**: Production deployment guide

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit changes** (`git commit -m 'Add amazing feature'`)
4. **Push to branch** (`git push origin feature/amazing-feature`)
5. **Open Pull Request**

### Development Setup
```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Install pre-commit hooks
pre-commit install

# Run tests before committing
python -m pytest tests/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“š Citation

If you use this work in your research, please cite:

```bibtex
@software{xai_lung_segmentation_2024,
  title={XAI Lung Segmentation Analysis: Explainable AI for Medical Image Segmentation},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/xai-lung-segmentation}
}
```

## ğŸ™ Acknowledgments

- **PyTorch Team** for the deep learning framework
- **Streamlit Team** for the interactive dashboard framework
- **Medical Imaging Community** for dataset contributions
- **XAI Research Community** for attribution method development

## ğŸ“§ Contact

- **Author**: Your Name
- **Email**: your.email@example.com
- **LinkedIn**: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- **GitHub**: [@yourusername](https://github.com/yourusername)

---

<p align="center">
  <strong>ğŸš€ Building Explainable AI for Medical Imaging ğŸš€</strong>
</p>